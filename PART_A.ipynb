{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PART_A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaygrao77/DeepLearning-Assignment2/blob/main/PART_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQHrzscZjmv_",
        "outputId": "8e6ae7b5-5ea0-4ad5-8788-aeedf804400b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.11-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 22.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 39.1 MB/s \n",
            "\u001b[?25hCollecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.8-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 43.0 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=b80762e05b04c16aacf1f43929485e0cff3ccde029fa72c1511eaeff49614523\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.8 setproctitle-1.2.2 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.11 yaspin-2.1.0\n"
          ]
        }
      ],
      "source": [
        "#Import and install required libraries\n",
        "import os\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ydeuXv4h7KwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TuvWgGwkuR0",
        "outputId": "fb6ea29c-ce25-463e-abb3-abea9eb88a02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip and load file data file onto server, then delete zip file for optimizing performance\n",
        "# zip_path = \"drive/MyDrive/nature_12K.zip\"\n",
        "# !cp \"{zip_path}\" .\n",
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip -q nature_12K.zip\n",
        "!rm nature_12K.zip"
      ],
      "metadata": {
        "id": "rq-vHP-llAzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9468242-37b5-45a0-ebe1-6635eb7a78a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-25 12:12:24--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.1.208, 142.250.65.80, 172.253.62.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.1.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G   122MB/s    in 26s     \n",
            "\n",
            "2022-03-25 12:12:50 (141 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n",
            "replace inaturalist_12K/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "A\n",
            "y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##  building of CNN Model\n",
        "def CNN_Model(num_filters=32, filter_multiplier=1, dropout=0.2, batch_norm=False, dense_size=64, num_classes=10, image_size=200):\n",
        "    cnn_model = Sequential()\n",
        "    \n",
        "    for i in range(5):\n",
        "        filter_dim = 11 - 2*i\n",
        "        filter_size = (filter_dim, filter_dim)\n",
        "        if i==0:\n",
        "            cnn_model.add(Conv2D(num_filters, filter_size, input_shape=(image_size, image_size, 3), data_format=\"channels_last\"))\n",
        "        else:\n",
        "            cnn_model.add(Conv2D(num_filters, filter_size))\n",
        "        if batch_norm:\n",
        "            cnn_model.add(BatchNormalization())\n",
        "        cnn_model.add(Activation(\"relu\"))\n",
        "        cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        num_filters = int(num_filters * filter_multiplier)\n",
        "    \n",
        "    cnn_model.add(Flatten())\n",
        "    cnn_model.add(Dense(dense_size))\n",
        "    cnn_model.add(Dropout(dropout))\n",
        "    cnn_model.add(Activation(\"relu\"))\n",
        "    cnn_model.add(Dense(num_classes))\n",
        "    cnn_model.add(Activation(\"softmax\"))\n",
        "\n",
        "    return cnn_model"
      ],
      "metadata": {
        "id": "CGlQYAwqrMBD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare the dataset for training\n",
        "def prepare_dataset(DATA_DIR=\"inaturalist_12K\", A\n",
        "                    =False):\n",
        "    train_dir = os.path.join(DATA_DIR, \"train\")\n",
        "    test_dir = os.path.join(DATA_DIR, \"val\")\n",
        "\n",
        "    if augment_data:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=90,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          validation_split=0.1,\n",
        "                                          horizontal_flip=True)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(200, 200), batch_size=256, subset=\"training\")\n",
        "    val_generator = train_datagen.flow_from_directory(train_dir, target_size=(200, 200), batch_size=256, subset=\"validation\")\n",
        "    test_generator = test_datagen.flow_from_directory(test_dir, target_size=(200, 200), batch_size=256)\n",
        "    \n",
        "    return train_generator, val_generator, test_generator;"
      ],
      "metadata": {
        "id": "R9U6xd1Z7NJF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Customise run names for WandB to enhance readability\n",
        "def setRunName(num_filters=32, filter_multiplier=1, augment_data=False, dropout=0.2, batch_norm=False):\n",
        "    \n",
        "    augment_data_options = {True: \"Y\", False: \"N\"}\n",
        "    batch_norm_options = {True: \"Y\", False: \"N\"}\n",
        "\n",
        "    run_name = \"_\".join([\"num\", str(num_filters), \"org\", str(filter_multiplier), \"aug\", augment_data_options[augment_data],\n",
        "                      \"drop\", str(dropout), \"norm\", batch_norm_options[batch_norm]])\n",
        "    \n",
        "    return run_name;"
      ],
      "metadata": {
        "id": "XYk6pP-w7Wj-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Integrate WandB with training and validation process\n",
        "def train():\n",
        "\n",
        "    config_defaults = {\n",
        "        \"num_filters\": 32,\n",
        "        \"filter_multiplier\": 2,\n",
        "        \"augment_data\": False,\n",
        "        \"dropout\": 0.3,\n",
        "        \"batch_norm\": False,\n",
        "        \"epochs\": 10,\n",
        "        \"dense_size\": 64,\n",
        "        \"lr\": 0.001\n",
        "    }\n",
        "    wandb.init(config=config_defaults, magic=True)\n",
        "    config = wandb.config\n",
        "    wandb.run.name = setRunName(config.num_filters, config.filter_multiplier, config.augment_data, config.dropout, config.batch_norm)\n",
        "\n",
        "    train_generator, val_generator, test_generator = prepare_dataset(augment_data=config.augment_data)\n",
        "    model = CNN_Model(num_filters=config.num_filters, filter_multiplier=config.filter_multiplier,\n",
        "                      dropout=config.dropout, batch_norm=config.batch_norm, dense_size=config.dense_size)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
        "    model.fit(train_generator, epochs=config.epochs, validation_data=val_generator, callbacks=[WandbCallback()])"
      ],
      "metadata": {
        "id": "JjNp8sEG7fA2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare training and test generators for testing\n",
        "def prepare_test_dataset(DATA_DIR=\"inaturalist_12K\", augment_data=False, image_size=200):\n",
        "    train_dir = os.path.join(DATA_DIR, \"train\")\n",
        "    test_dir = os.path.join(DATA_DIR, \"val\")\n",
        "\n",
        "    if augment_data:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=90,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          horizontal_flip=True)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(image_size, image_size), batch_size=256)\n",
        "    test_generator = test_datagen.flow_from_directory(test_dir, target_size=(image_size, image_size), batch_size=30)\n",
        "    \n",
        "    return train_generator, test_generator;"
      ],
      "metadata": {
        "id": "SmaUZOtm7-kA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display sample test images with their predictions and labels\n",
        "def plot_test_results(test_data, predictions, labels):\n",
        "    fig, ax = plt.subplots(nrows=5, ncols=6, figsize=(15,15))\n",
        "    output_map = {0: 'Amphibia', 1: 'Animalia', 2: 'Arachnida', 3: 'Aves', 4: 'Fungi', \n",
        "                  5: 'Insecta', 6: 'Mammalia', 7: 'Mollusca', 8: 'Plantae', 9: 'Reptilia'}\n",
        "    for i in range(30):\n",
        "        img = test_data[0][0][i]\n",
        "        ax[int(i/6), i%6].imshow(img)\n",
        "        ax[int(i/6), i%6].axis('off')\n",
        "        ax[int(i/6), i%6].set_aspect('equal')\n",
        "        ax[int(i/6), i%6].set_title(\"Predicted: \" + output_map[np.argmax(predictions, axis=1)[i]] + \"\\nLabel: \" + output_map[np.argmax(labels, axis=1)[i]])"
      ],
      "metadata": {
        "id": "q6lP52Hv8CvH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise feature maps from the first Conv layer for a test image\n",
        "def plot_filters(model, test_data, sample_num):\n",
        "    sub_model = Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
        "    plt.imshow(test_data[0][0][sample_num])\n",
        "    plt.axis('off')\n",
        "    feature_maps = sub_model(test_data[0][0])\n",
        "    fig, ax = plt.subplots(4, 8, figsize=(12,6))\n",
        "    for i in range(feature_maps.shape[-1]):\n",
        "        ax[int(i/8), i%8].imshow(feature_maps[sample_num, :, :, i], cmap='gray')\n",
        "        ax[int(i/8), i%8].axis('off')"
      ],
      "metadata": {
        "id": "4Rkk0p7V8G8v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Integrate WandB with testing and evaluation process\n",
        "def test():\n",
        "\n",
        "    config_defaults = {\n",
        "        \"num_filters\": 32,\n",
        "        \"filter_multiplier\": 2,\n",
        "        \"augment_data\": True,\n",
        "        \"dropout\": 0.3,\n",
        "        \"batch_norm\": True,\n",
        "        \"epochs\": 10,\n",
        "        \"dense_size\": 64,\n",
        "        \"lr\": 0.001\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_defaults, magic=True)\n",
        "    config = wandb.config\n",
        "    wandb.run.name = setRunName(config.num_filters, config.filter_multiplier, config.augment_data, config.dropout, config.batch_norm)\n",
        "\n",
        "    train_generator, test_generator = prepare_test_dataset(augment_data=config.augment_data, image_size=256)\n",
        "    model = CNN_Model(num_filters=config.num_filters, filter_multiplier=config.filter_multiplier,\n",
        "                      dropout=config.dropout, batch_norm=config.batch_norm, dense_size=config.dense_size, image_size=256)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=\"categorical_crossentropy\", metrics=\"categorical_accuracy\")\n",
        "    model.fit(train_generator, epochs=config.epochs, callbacks=[WandbCallback()])\n",
        "\n",
        "    print(\"Evaluating Model:\")\n",
        "    model.evaluate(test_generator, batch_size=256)\n",
        "    predictions = model(test_generator[0][0])\n",
        "    plot_test_results(test_generator, predictions, test_generator[0][1])\n",
        "    sample_num = 11\n",
        "    plot_filters(model, test_generator, sample_num)\n",
        "    model.save(\"Best_model.h5\")"
      ],
      "metadata": {
        "id": "IWEO2UXU8OpU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ho8EHOXVBCYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}